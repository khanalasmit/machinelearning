{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ae67ad",
   "metadata": {},
   "source": [
    "### **AdaBoost step by step**\n",
    "|X1|X2|y|Remark|Weight|\n",
    "|-|-|-|-|-|\n",
    "|3|7|1|n=5|0.2|\n",
    "|2|9|0|weight=1/n i.e 0.2|\n",
    "|1|4|1||0.2|\n",
    "|9|8|0||0.2|\n",
    "|3|7|0||0.2|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2631a7",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- first we find the decsion stumps at the first stage taking the depth of the decision tree 1.\n",
    "- then we calculate the value of $\\alpha$ it is basically error rate\n",
    "-  The graph is as follows\\\n",
    "![image](2.png)\n",
    "- The function to define this graph is: $\\alpha=\\frac{1}{2}ln(\\frac{1-error}{error})$\n",
    "- Now in the next step, how do we calculate the error:\n",
    "Consider we have two error points, then error will be the sum of the weights. Thus for the first stage error will be 0.4 for the above given data. Then we will get the value of the $\\alpha=0.2$. \n",
    "- Then we will propagte the mistakes to the next stage. The process we use will be the upsampling. We boost the misclasiffied. We decerase the weight for the correctly predicted data and increase the weight for the incorrecly classified data. \\\n",
    "<u>*For misclassified data*</u>\\\n",
    "new_wt=current_wt* $e^{\\alpha_{1}}$\\\n",
    "<u>*For correctly classified data*</u>\\\n",
    "new_wt=current_wt*$e^{-\\alpha_{1}}$\n",
    "- Then we need to normalize the weights to make the total sum 1. \n",
    "- Then to do the upsampling:\\\n",
    "We create the ranges of the weight. We will create random numbers between 0 and 1. Then we will find which random numbers falls in which range. We note each of the row numbers and create a dataset with only those rows.\n",
    "- Here we may have a row repeating mostly. The row with highest error or weight will have the highest probablity of getting selected. This is called up sampling i.e Selecting erronous data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
