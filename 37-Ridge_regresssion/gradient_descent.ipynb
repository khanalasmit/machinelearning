{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aea996",
   "metadata": {},
   "source": [
    "### **RIDGE REGRESSION USING THE GRADIENT DESCENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7152f",
   "metadata": {},
   "source": [
    "$$\n",
    "W_{new} = W_{old} - \\eta \\frac{\\delta L}{\\delta W}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\delta L}{\\delta W} =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\delta L}{\\delta W_0} \\\\\n",
    "\\frac{\\delta L}{\\delta W_1} \\\\\n",
    "\\frac{\\delta L}{\\delta W_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\delta L}{\\delta W_n}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817e583",
   "metadata": {},
   "source": [
    "$$\n",
    "L=\\frac{1}{2}(XW-Y)^{T}(XW-Y)+\\frac{1}{2} \\lambda W^{T}W\\\\[6pt]\n",
    "=\\frac{1}{2}(W^{T}X^{T}-Y^{T})(XW-Y)+\\frac{1}{2}W^{T}W\\\\[6pt]\n",
    "=\\frac{1}{2}\\left [W^{T}X^{T}XW-W^{T}X^{T}Y-Y^{T}WX+Y^{T}Y\\right] +\\frac{1}{2}\\lambda W^{T}W\\\\[6pt]\n",
    "\\text{Now,}\\\\\n",
    "\\frac{dL}{dW}=X^{T}XW-Y^{T}X+\\lambda W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1014d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee249920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03807591  0.05068012  0.06169621 ... -0.00259226  0.01990749\n",
      "  -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 ... -0.03949338 -0.06833155\n",
      "  -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 ... -0.00259226  0.00286131\n",
      "  -0.02593034]\n",
      " ...\n",
      " [ 0.04170844  0.05068012 -0.01590626 ... -0.01107952 -0.04688253\n",
      "   0.01549073]\n",
      " [-0.04547248 -0.04464164  0.03906215 ...  0.02655962  0.04452873\n",
      "  -0.02593034]\n",
      " [-0.04547248 -0.04464164 -0.0730303  ... -0.03949338 -0.00422151\n",
      "   0.00306441]] [151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n",
      " 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n",
      " 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n",
      "  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n",
      "  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n",
      "  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n",
      "  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n",
      "  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n",
      " 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n",
      "  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n",
      " 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n",
      " 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n",
      " 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n",
      " 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n",
      "  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n",
      " 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n",
      "  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n",
      " 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n",
      "  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n",
      "  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n",
      " 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n",
      "  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n",
      " 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n",
      " 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n",
      " 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n",
      " 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n",
      " 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n",
      " 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n",
      " 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n",
      "  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n",
      " 146. 212. 233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.\n",
      "  49.  64.  48. 178. 104. 132. 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "X,y=load_diabetes(return_X_y=True)\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a01f7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c3d7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d209aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = SGDRegressor(penalty='l2', max_iter=500, eta0=0.01, learning_rate='constant', alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81a23434",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train,y_train)\n",
    "y_pred=reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a306ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31d91869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score: 0.4636272139331197\n",
      "[  58.36617803  -90.71284819  360.03710249  250.73074919   -4.6551171\n",
      "  -26.56573338 -191.60556016  152.66541276  254.24540556  142.69416678]\n",
      "[154.28144788]\n"
     ]
    }
   ],
   "source": [
    "print('R2_score:',r2_score(y_test,y_pred))\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "720b81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "reg2=Ridge(alpha=0.001,max_iter=500,solver='sparse_cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd6748be",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2.fit(X_train,y_train)\n",
    "y_pred2=reg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "880e5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score: 0.477500301886152\n",
      "[  30.28001864 -260.63403698  548.0370512   386.91677392 -794.28917858\n",
      "  423.10454803   73.36311698  272.64578919  617.16129186   42.90483206]\n",
      "150.9971936115795\n"
     ]
    }
   ],
   "source": [
    "print(\"R2_score:\",r2_score(y_test,y_pred2))\n",
    "print(reg2.coef_)\n",
    "print(reg2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6501b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OwnRidge:\n",
    "    def __init__(self,alpha,learning_rate,epochs):\n",
    "        self.alpha=alpha\n",
    "        self.coef_=None\n",
    "        self.intercept_=None\n",
    "        self.learning_rate=learning_rate\n",
    "        self.epochs=epochs\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.coef_=np.ones(X_train.shape[1])\n",
    "        self.intercept_=0\n",
    "        thetha=np.insert(self.coef_,0,self.intercept_)\n",
    "        X_train=np.insert(X_train,0,1,axis=1)#inserts the columns of 1 at the begining of the columns that is at zero\n",
    "        for i in range(self.epochs):\n",
    "            thetha_der=(X_train.T@X_train).dot(thetha)-y_train.T@X_train+self.alpha*thetha\n",
    "            thetha=thetha-self.learning_rate*thetha_der\n",
    "        self.coef_=thetha[1:]\n",
    "        self.intercept_=thetha[0]\n",
    "    def predict(self,X_test):\n",
    "        return X_test@self.coef_+self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7a335e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg3=OwnRidge(0.001,0.005,500)\n",
    "reg3.fit(X_train,y_train)\n",
    "y_pred3=reg3.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcf00771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score: 0.4797581802542319\n",
      "[  46.31716214 -187.24884223  491.34427528  330.58457492  -66.25996929\n",
      "  -91.79013531 -229.29992352  152.26539917  315.37191969  121.79148056]\n",
      "150.9465502867705\n"
     ]
    }
   ],
   "source": [
    "print(\"R2_score:\",r2_score(y_test,y_pred3))\n",
    "print(reg3.coef_)\n",
    "print(reg3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f9a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
