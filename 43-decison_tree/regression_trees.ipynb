{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e2f035",
   "metadata": {},
   "source": [
    "### **REGRESSION TREES**\n",
    "\n",
    "- When we have clustered regression-like data, we use regression trees rather than linear regression.\n",
    "\n",
    "---\n",
    "\n",
    "# 🌳 Regression Trees: Complete Guide\n",
    "\n",
    "A **Regression Tree** is a decision tree algorithm used for predicting **continuous values** (like house price, temperature, etc.). It splits the dataset into **regions** using decision rules based on input features and predicts the output using the **mean value** of samples in each region.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 How Does a Regression Tree Work?\n",
    "\n",
    "1. Start with the entire dataset.\n",
    "2. For each feature, try **all possible split points** (midpoints between unique values).\n",
    "3. At each split, compute the **error** (usually **Mean Squared Error** or MSE).\n",
    "4. Choose the split that gives the **lowest total error**.\n",
    "5. Repeat the process recursively on resulting subsets (left and right).\n",
    "6. Stop when a stopping criterion (like depth or min samples per leaf) is met.\n",
    "7. At prediction time, the **mean of the leaf node** is used as output.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Example Dataset (Three Clusters)\n",
    "\n",
    "Let’s say the target values (`y`) form 3 natural clusters:\n",
    "\n",
    "| X  | y    |\n",
    "|----|------|\n",
    "| 1  | 2    |\n",
    "| 2  | 1.5  |\n",
    "| 3  | 2.5  |\n",
    "| 6  | 6    |\n",
    "| 7  | 6.5  |\n",
    "| 8  | 5.5  |\n",
    "| 11 | 10   |\n",
    "| 12 | 11   |\n",
    "| 13 | 10.5 |\n",
    "\n",
    "📌 You can visualize this as 3 groups (clusters) centered at:\n",
    "- Cluster 1: Around 2\n",
    "- Cluster 2: Around 6\n",
    "- Cluster 3: Around 10.5\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Step-by-Step: Finding the Best Split\n",
    "\n",
    "### Step 1: Sort the data by X:\n",
    "\n",
    "| X  | y    |\n",
    "|----|------|\n",
    "| 1  | 2    |\n",
    "| 2  | 1.5  |\n",
    "| 3  | 2.5  |\n",
    "| 6  | 6    |\n",
    "| 7  | 6.5  |\n",
    "| 8  | 5.5  |\n",
    "| 11 | 10   |\n",
    "| 12 | 11   |\n",
    "| 13 | 10.5 |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Try all split points (between X values)\n",
    "\n",
    "Possible split points = midpoints:\n",
    "\n",
    "- 1.5, 2.5, 4.5, 6.5, 7.5, 9.5, 11.5, 12.5\n",
    "\n",
    "At each split:\n",
    "- Split data into Left and Right based on `X <= split`\n",
    "- Compute **MSE** of each part\n",
    "- Total Error = (Left_MSE × n_L + Right_MSE × n_R) / n\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Splitting Point Intuition\n",
    "\n",
    "A **splitting point** is simply a **threshold** on a feature (X) such that the dataset is divided into two groups:\n",
    "\n",
    "- The valleys in the graph show **ideal split points**.\n",
    "- Since our data has **3 natural clusters**, we expect **2 local minima** in the error plot → one between cluster 1 & 2, and another between cluster 2 & 3.\n",
    "\n",
    "### Example: Split at X = 4.5\n",
    "\n",
    "**Left (X ≤ 4.5):** [1, 2, 3] → y = [2, 1.5, 2.5], Mean = 2, MSE = 0.166  \n",
    "**Right (X > 4.5):** [6, 7, 8, 11, 12, 13] → y = [6, 6.5, 5.5, 10, 11, 10.5], Mean = 8.25, MSE ≈ 4.56\n",
    "\n",
    "**Weighted MSE:**  \n",
    "Total = (3/9)×0.166 + (6/9)×4.56 ≈ **3.08**\n",
    "\n",
    "Try all splits, and the one with **lowest total error** is selected.\n",
    "\n",
    "---\n",
    "\n",
    "# 🌳 Regression Trees: Splitting Criteria and Error Calculation\n",
    "\n",
    "This walkthrough explains how **Regression Trees** choose the best split by minimizing **Mean Squared Error (MSE)**. We’ll go through **manual calculations** and then visualize results with code.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Dataset\n",
    "\n",
    "We want to predict `marks` based on `hours studied`.\n",
    "\n",
    "| Hours (X) | Marks (y) |\n",
    "|-----------|-----------|\n",
    "| 1         | 22        |\n",
    "| 2         | 24        |\n",
    "| 2.5       | 21        |\n",
    "| 3         | 23        |\n",
    "| 4         | 50        |\n",
    "| 5         | 48        |\n",
    "| 6         | 47        |\n",
    "| 7         | 80        |\n",
    "| 8         | 78        |\n",
    "| 9         | 82        |\n",
    "\n",
    "---\n",
    "\n",
    "## 📏 Step 1: Try Split at X = 3.5\n",
    "\n",
    "Split the data:\n",
    "- **Left group** (X ≤ 3.5): [22, 24, 21, 23]\n",
    "- **Right group** (X > 3.5): [50, 48, 47, 80, 78, 82]\n",
    "\n",
    "### ➤ Left Group (n = 4)\n",
    "\n",
    "Mean:\n",
    "$$\n",
    "\\bar{y}_L = \\frac{22 + 24 + 21 + 23}{4} = 22.5\n",
    "$$\n",
    "\n",
    "MSE:\n",
    "$$\n",
    "\\text{MSE}_L = \\frac{(22 - 22.5)^2 + (24 - 22.5)^2 + (21 - 22.5)^2 + (23 - 22.5)^2}{4} \\\\\n",
    "= \\frac{0.25 + 2.25 + 2.25 + 0.25}{4} = \\frac{5}{4} = 1.25\n",
    "$$\n",
    "\n",
    "### ➤ Right Group (n = 6)\n",
    "\n",
    "Mean:\n",
    "$$\n",
    "\\bar{y}_R = \\frac{50 + 48 + 47 + 80 + 78 + 82}{6} = 64.17\n",
    "$$\n",
    "\n",
    "MSE:\n",
    "$$\n",
    "= \\frac{(50 - 64.17)^2 + (48 - 64.17)^2 + \\ldots + (82 - 64.17)^2}{6} \\\\\n",
    "≈ \\frac{203.5 + 262.4 + 295.1 + 250.3 + 191.7 + 316.4}{6} ≈ 253.23\n",
    "$$\n",
    "\n",
    "### ➤ Total MSE\n",
    "\n",
    "$$\n",
    "\\text{Total MSE} = \\frac{4}{10} \\cdot 1.25 + \\frac{6}{10} \\cdot 253.23 = 0.5 + 151.94 = 152.44\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 📏 Step 2: Try Split at X = 6.5\n",
    "\n",
    "Split:\n",
    "- **Left (X ≤ 6.5):** [22, 24, 21, 23, 50, 48, 47]\n",
    "- **Right (X > 6.5):** [80, 78, 82]\n",
    "\n",
    "### ➤ Left Group (n = 7)\n",
    "\n",
    "Mean:\n",
    "$$\n",
    "\\bar{y}_L = 33.57\n",
    "$$\n",
    "\n",
    "MSE ≈ 172.2\n",
    "\n",
    "### ➤ Right Group (n = 3)\n",
    "\n",
    "Mean = 80\n",
    "\n",
    "MSE:\n",
    "$$\n",
    "= \\frac{(80-80)^2 + (78-80)^2 + (82-80)^2}{3} = \\frac{0 + 4 + 4}{3} = 2.67\n",
    "$$\n",
    "\n",
    "### ➤ Total MSE\n",
    "\n",
    "$$\n",
    "= \\frac{7}{10} \\cdot 172.2 + \\frac{3}{10} \\cdot 2.67 ≈ 121.34\n",
    "$$\n",
    "\n",
    "✅ **Better than 152.44**, so this is a better split.\n",
    "\n",
    "---\n",
    "\n",
    "## 📉 Final Visualization: Error vs Split Point\n",
    "\n",
    "Below is Python code to try **all split points**, compute **total MSE**, and plot the result.\n",
    "\n",
    "---\n",
    "\n",
    "## 🐍 Python Code\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Dataset\n",
    "X = np.array([1, 2, 2.5, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([22, 24, 21, 23, 50, 48, 47, 80, 78, 82])\n",
    "\n",
    "# Step 2: MSE calculation function\n",
    "def mse(values):\n",
    "    if len(values) == 0:\n",
    "        return 0\n",
    "    return np.mean((values - np.mean(values))**2)\n",
    "\n",
    "# Step 3: Try all split points\n",
    "split_points = (X[:-1] + X[1:]) / 2\n",
    "errors = []\n",
    "\n",
    "for split in split_points:\n",
    "    left = y[X <= split]\n",
    "    right = y[X > split]\n",
    "\n",
    "    # Optional: apply min_samples_leaf condition\n",
    "    if len(left) >= 2 and len(right) >= 2:\n",
    "        total_error = (len(left)/len(y))*mse(left) + (len(right)/len(y))*mse(right)\n",
    "    else:\n",
    "        total_error = float('inf')  # Penalize bad splits\n",
    "\n",
    "    errors.append(total_error)\n",
    "\n",
    "# Step 4: Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(split_points, errors, marker='o')\n",
    "plt.title(\"📉 Error vs Split Point\")\n",
    "plt.xlabel(\"Split Point (Hours Studied)\")\n",
    "plt.ylabel(\"Total MSE\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8fd64",
   "metadata": {},
   "source": [
    "# 🌳 Regression Tree: Choosing the Best Split Feature with Calculation\n",
    "\n",
    "We are building a regression tree to predict `Marks` using two features:\n",
    "- `Hours` (hours studied)\n",
    "- `CGPA` (prior GPA)\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 Dataset\n",
    "\n",
    "| Index | Hours | CGPA | Marks |\n",
    "|-------|-------|------|-------|\n",
    "| 0     | 1     | 2.1  | 22    |\n",
    "| 1     | 2     | 2.5  | 24    |\n",
    "| 2     | 2.5   | 2.4  | 21    |\n",
    "| 3     | 3     | 2.6  | 23    |\n",
    "| 4     | 4     | 3.2  | 50    |\n",
    "| 5     | 5     | 3.1  | 48    |\n",
    "| 6     | 6     | 3.3  | 47    |\n",
    "| 7     | 7     | 3.9  | 80    |\n",
    "| 8     | 8     | 3.8  | 78    |\n",
    "| 9     | 9     | 4.0  | 82    |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 Step-by-step: Split on Hours\n",
    "\n",
    "Let’s try a split at Hours = 4.5\n",
    "\n",
    "Split groups:\n",
    "- Left Group (≤ 4.5): Hours = [1, 2, 2.5, 3, 4] → Marks = [22, 24, 21, 23, 50]\n",
    "- Right Group (> 4.5): Hours = [5, 6, 7, 8, 9] → Marks = [48, 47, 80, 78, 82]\n",
    "\n",
    "Mean Left = (22+24+21+23+50)/5 = 28  \n",
    "MSE Left = [(22-28)² + (24-28)² + (21-28)² + (23-28)² + (50-28)²]/5  \n",
    "         = [36 + 16 + 49 + 25 + 484] / 5 = 122 / 5 = 122.0\n",
    "\n",
    "Mean Right = (48+47+80+78+82)/5 = 67  \n",
    "MSE Right = [(48-67)² + (47-67)² + (80-67)² + (78-67)² + (82-67)²]/5  \n",
    "          = [361 + 400 + 169 + 121 + 225] / 5 = 1276 / 5 = 255.2\n",
    "\n",
    "Weighted Total MSE = (5/10)×122 + (5/10)×255.2 = 61 + 127.6 = 188.6\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Try Split on CGPA = 3.15\n",
    "\n",
    "Left: CGPA ≤ 3.15 → [2.1, 2.5, 2.4, 2.6, 3.2, 3.1] → Marks = [22, 24, 21, 23, 50, 48]  \n",
    "Right: CGPA > 3.15 → [3.3, 3.9, 3.8, 4.0] → Marks = [47, 80, 78, 82]\n",
    "\n",
    "Mean Left = 31.33  \n",
    "MSE Left = avg of [(22-31.33)², ..., (48-31.33)²]  \n",
    "         ≈ [87.1, 54.0, 108.1, 69.4, 345.8, 275.8] → Sum ≈ 940.2 → MSE = 940.2/6 ≈ 156.7\n",
    "\n",
    "Mean Right = 71.75  \n",
    "MSE Right = [(47-71.75)² + ...]  \n",
    "          ≈ [615.1, 68.1, 38.8, 104.1] → Sum = 826.1 → MSE = 206.5\n",
    "\n",
    "Weighted Total MSE = (6/10)×156.7 + (4/10)×206.5 = 94.02 + 82.6 = 176.62\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Final Decision\n",
    "\n",
    "- MSE for split on Hours at 4.5 = 188.6\n",
    "- MSE for split on CGPA at 3.15 = 176.62\n",
    "\n",
    "→ Choose CGPA ≤ 3.15 because it gives lower error.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Code to Visualize MSE\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Hours = np.array([1, 2, 2.5, 3, 4, 5, 6, 7, 8, 9])\n",
    "CGPA = np.array([2.1, 2.5, 2.4, 2.6, 3.2, 3.1, 3.3, 3.9, 3.8, 4.0])\n",
    "Marks = np.array([22, 24, 21, 23, 50, 48, 47, 80, 78, 82])\n",
    "\n",
    "def mse(y):\n",
    "    return np.mean((y - np.mean(y))**2) if len(y) > 0 else 0\n",
    "\n",
    "def split_errors(X, y):\n",
    "    sps = (X[:-1] + X[1:]) / 2\n",
    "    errors = []\n",
    "    for sp in sps:\n",
    "        left = y[X <= sp]\n",
    "        right = y[X > sp]\n",
    "        total_error = (len(left)/len(y))*mse(left) + (len(right)/len(y))*mse(right)\n",
    "        errors.append(total_error)\n",
    "    return sps, errors\n",
    "\n",
    "sps_h, err_h = split_errors(Hours, Marks)\n",
    "sps_c, err_c = split_errors(CGPA, Marks)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(sps_h, err_h, label=\"Hours\", marker='o')\n",
    "plt.plot(sps_c, err_c, label=\"CGPA\", marker='s')\n",
    "plt.title(\"MSE vs Split Point\")\n",
    "plt.xlabel(\"Split Point\")\n",
    "plt.ylabel(\"Total MSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
