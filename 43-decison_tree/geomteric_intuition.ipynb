{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b100a972",
   "metadata": {},
   "source": [
    "## **DECISION TREE CLASSIFIER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f5392",
   "metadata": {},
   "source": [
    "In the simple form we can say that decison trees are the nested if else statements.\\\n",
    "**Where is the tree in the Decision tree?**\n",
    "- We form the tree like structure from the if else statements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206623c",
   "metadata": {},
   "source": [
    "**What if we have numerical data?**\n",
    "- For example in the iris datasets, we create classes of the numerical data. Then we divide the data accrodingly creating the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64542ee4",
   "metadata": {},
   "source": [
    "### **GEOMETRIC INTUITION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c3b1c",
   "metadata": {},
   "source": [
    "![image](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df95ba5c",
   "metadata": {},
   "source": [
    "### **Pseudo code**\n",
    "- Begin with the training dataset, whcih should have some feature variables and classification or regresssion output. \n",
    "- Determine the **Best Feature** in the dataset to split the data on; more on how we define **Best Feature** later.\n",
    "- Split the data into the subsets that contain the correct value for this best feature. This splitting basically defines a node on the tree i.e each node is a splitting point based on a certain feature from out data.\n",
    "- Recursively generate new tree nodes by using the subset of data created from step 3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d5433",
   "metadata": {},
   "source": [
    "### **Tree stucture**\n",
    "- The base decesion factor is root node.\n",
    "- Splitting point\n",
    "- The nodes in middle are called Decision node\n",
    "- The bottom classifying nodes are the Leaf nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410edc5",
   "metadata": {},
   "source": [
    "### **Advantages**\n",
    "- Intuitive and easy to understand.\n",
    "- Minimal data preperation is required.\n",
    "- The cost of using the tree for inference is **logarithmic** in the number of data points used to train the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218ab04",
   "metadata": {},
   "source": [
    "### **Disadvantages**\n",
    "- Overfitting \n",
    "- Prone to error for imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71307a",
   "metadata": {},
   "source": [
    "### **CART-Classification and Regression Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0760e0a",
   "metadata": {},
   "source": [
    "### **DECISON TREES ENTROPY**\n",
    "In the most layman terms, Entropy is nothing but the measure of disorder. Or you cna also call it the measure of "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
