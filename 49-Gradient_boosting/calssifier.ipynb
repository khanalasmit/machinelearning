{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb83767",
   "metadata": {},
   "source": [
    "## **GRADIENT BOOSTING CLASSIFIER**\n",
    "- The algorithm we use will be same as the gradient boost regressor. The only difference would be the use of the log loss function rather than least square or loss. \n",
    "- First what is happening or overview is presented here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18967597",
   "metadata": {},
   "source": [
    "|**CGPA**|**iq**|**is_placed**|\n",
    "|-|-|-|\n",
    "|6.82|118|0|\n",
    "|6.36|125|1|\n",
    "|5.39|99|1|\n",
    "|5.50|106|1|\n",
    "|6.39|148|0|\n",
    "|9.13|148|1|\n",
    "|7.17|147|1|\n",
    "|7.72|72|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739b96a",
   "metadata": {},
   "source": [
    "- Here we will use multiple smaller base models and add the results for the final model.\n",
    "- here For the example above three base models will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b3801",
   "metadata": {},
   "source": [
    "The final Boosting model will be:\\\n",
    "$F(x)=f_0(x)+f_1(x)+f_2(x)$\n",
    "- The first model will be the simple model and the two later models are the decision tree models.\n",
    "- In the first stage first model is fitted than later the combintion of the first are fitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6d736",
   "metadata": {},
   "source": [
    "**For the first model**:\n",
    "- Here log(odds) is calcualted.\n",
    "- The number of ones are calculated and are divided by the number of the zeros and log is taken for the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048e2b5",
   "metadata": {},
   "source": [
    "- for the dataset above, we will get  the log odd as \n",
    "$log(5/3)=0.51$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed83c7c",
   "metadata": {},
   "source": [
    "- Now from the log of odds the probablity is calulated as \\\n",
    "$p=\\frac{1}{1+e^{-log(odds)}}$\n",
    "- probalbity comes out to be 0.625\n",
    "- Now consider the threshold value be 0.5 i.e <0.5 means 0 and 0.5> is 1.\n",
    "- This means that model always predicsts 1.\n",
    "- Although this is not correct this is a good starting point since the datasets has majority 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5ddf8",
   "metadata": {},
   "source": [
    "**For the second stage**\n",
    "- Here we caluclate the residul by subtracting the true value with residual predicted probablity.\n",
    "- Then the y becomes residual1 and the we fit the regression tree, which should be weak learner i.e tree depth very small.\n",
    "- The decision tree as the second model is gives the log probalbity as we have fitted the probablity.\n",
    "- Here we need to do $f_1(X)+dt$ but here thorugh dt we obtiai probablity we cannot directly do $f_1(X)+dt$\n",
    "- Thus we need to convert to log of odds\n",
    "- Thus we need to apply the formula\n",
    "$$\\frac{\\sum Residual}{\\sum \\left[PreviousProb*(1-PreviousProb)\\right]}$$\n",
    "- The decision tree may split multiple rows in the single node \n",
    "- Thus there is the function in the scikit learn for that function\n",
    "- The data with leaf entry is as shown in the dataset.\n",
    "- Then the overall output after the application of the formula is also shown below.\n",
    "- Then the pred2 probablity are calulated again as res2 as shown in the table below usign the formula above.\n",
    "- These residuals are then fed to the third model as above to find the third prediction probablity.\n",
    "- Here we see that jump is to high between two residuals\n",
    "- This may lead to overfitting \n",
    "- Thus learning rate is introduced in the second third and the consecutive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47229ca3",
   "metadata": {},
   "source": [
    "Then the dataset becomes\n",
    "|**CGPA**|**iq**|**is_placed**|**pre(log_odds)**|**probablity**|**residual (is_placed - probablity)**|**leaf_entry1**|**Pred2**|\n",
    "|-|-|-|-|-|-|-|-|\n",
    "|6.82|118|0|0.51|0.625|-0.625|3|-2.159|\n",
    "|6.36|125|1|0.51|0.625|0.375|1|2.110826|\n",
    "|5.39|99|1|0.51|0.625|0.375|1|2.110826|\n",
    "|5.50|106|1|0.51|0.625|0.375|1|2.110826|\n",
    "|6.39|148|0|0.51|0.625|-0.625|4|0.690826|\n",
    "|9.13|148|1|0.51|0.625|0.375|4|0.690826|\n",
    "|7.17|147|1|0.51|0.625|0.375|4|0.690826|\n",
    "|7.72|72|0|0.51|0.625|-0.625|3|0.690826|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
